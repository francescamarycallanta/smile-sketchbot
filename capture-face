# ---------- IMPORT LIBRARIES ----------
import cv2          # OpenCV library for computer vision (face, eye, smile detection)
import time         # For timing and delays
from picamera2 import Picamera2  # Raspberry Pi camera module

# ---------- INITIALIZE CAMERA ----------
# Create a camera object
picam2 = Picamera2()

# Configure camera for preview
# Resolution: 1280x720, Color format: XRGB8888
picam2.configure(
    picam2.create_preview_configuration(
        main={"format": "XRGB8888", "size": (1280, 720)}
    )
)
picam2.start()  # Start camera preview

# ---------- LOAD HAAR CASCADE DETECTORS ----------
# Pre-trained XML files for detecting face, eyes, and smiles
face_detector = cv2.CascadeClassifier(
    '/home/calla/opencv-4.x/data/haarcascades/haarcascade_frontalface_alt2.xml'
)
eye_detector = cv2.CascadeClassifier(
    '/home/calla/opencv-4.x/data/haarcascades/haarcascade_eye.xml'
)
smile_detector = cv2.CascadeClassifier(  # (currently unused but loaded for future)
    '/home/calla/opencv-4.x/data/haarcascades/haarcascade_smile.xml'
)

cv2.startWindowThread()  # Needed for Raspberry Pi GUI windows

# Counter to check how long a face stays visible
frames_with_face = 0

# ---------- MAIN LOOP ----------
while True:
    # Capture a frame from the Raspberry Pi camera
    im = picam2.capture_array()

    # Convert frame to grayscale (Haar cascades work best on gray images)
    grey = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)

    # Detect faces in the image
    # scaleFactor=1.1 → resize image each pass
    # minNeighbors=5 → higher value = stricter detection
    faces = face_detector.detectMultiScale(grey, scaleFactor=1.1, minNeighbors=5)

    # ---------- CHECK IF A FACE IS PRESENT ----------
    if len(faces) > 0:
        frames_with_face += 1  # Increase count if face detected
    else:
        frames_with_face = 0   # Reset if no face detected

    # ---------- PROCESS EACH DETECTED FACE ----------
    for (x, y, w, h) in faces:
        # Extract the region of interest (ROI) = detected face area
        roi_gray = grey[y:y + h, x:x + w]

        # Detect eyes inside the face area
        eyes = eye_detector.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=10)

        # "Mask out" the eyes by setting pixels to 0 (optional artistic effect)
        for (ex, ey, ew, eh) in eyes:
            roi_gray[ey:ey + eh, ex:ex + ew] = 0

        # Apply Canny edge detection to highlight the outline of the face
        edges = cv2.Canny(roi_gray, 100, 200)

        # Find contours (lines/shapes) from the edge-detected image
        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    # ---------- SHOW LIVE CAMERA FEED ----------
    cv2.imshow("Camera", im)

    # ---------- CAPTURE IMAGE WHEN FACE IS STEADY ----------
    # If a face has been detected for 10 consecutive frames:
    if frames_with_face >= 10:
        time.sleep(3)  # Wait 3 seconds to give the user time to smile fully

        # Get image size
        height, width = im.shape[:2]
        center_x, center_y = width // 2, height // 2

        # Define a square crop region (220x220 pixels) around the center
        crop_size = 220
        x1 = max(center_x - crop_size // 2, 0)
        y1 = max(center_y - crop_size // 2, 0)
        x2 = min(center_x + crop_size // 2, width)
        y2 = min(center_y + crop_size // 2, height)

        # Crop the image to focus on the face
        cropped = im[y1:y2, x1:x2]

        # Save the cropped face image to disk
        cv2.imwrite("/home/calla/Documents/processed_face.png", cropped)

        # Stop the camera and break the loop after saving
        picam2.stop()
        break

    # ---------- EXIT MANUALLY ----------
    # If the user presses the 'q' key, exit immediately
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ---------- CLEANUP ----------
cv2.destroyAllWindows()
